# Crawler/Indexer (title needs refinement)

Image placeholder

## Characteristics
The Crawler/Automated Indexer is a service which continually scans the Internet for new or updated scholarly items.  Upon discovering items that it determines to be scholarly items, it attempts to discern item metadata, and adds these items to its searchable index available for searching by the general public.  The Crawler/Automated Indexer will only index sites and items that meet certain criteria (e.g. [Google Scholar Inclusion Guidelines](https://scholar.google.com/intl/us/scholar/inclusion.html))

## Goals
1. Items added to the system should all be successfully indexed by Google Scholar and other indexes that we decide we wish to be indexed by.
2. Items added to the system should be indexed by Google Scholar (and others) in as short a timeframe as feasible
3. When item metadata is updated, the updates should be reflected by Google Scholar in as short a timeframe as feasible.
4. When an item is removed from public view, the item should disappear from Google Scholar's index in a reasonable amount of time.
5. Items' file attachments should not be crawled and available via "wayback" type caches.  This is to reduce the likelihood of lingering copies when an item is later removed from public view.
